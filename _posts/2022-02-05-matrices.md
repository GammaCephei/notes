---
toc: true
layout: post
description: Matrix properties and Operations
categories: [math, linear-algebra, matrix, introduction]
title: Matrix Properties and Operations
---

# Matrices

## Norms - Frobenius Norm

$||\boldsymbol{X}||{_F} = \sqrt{\displaystyle\sum_{i,j} X_{i,j}{^2} }$

For i rows, and j columns, sum the square of each element, then take the square root. This is analogous to the $L^2$ norm of vectors, and measures the Euclidean size of the matrix. Can also be thought of as the sum of the magnitude of all the vectors in $\boldsymbol{X}$.

## Multiplication

Number of columns in the first matrix must match the number of rows in the second, i.e. in the following example, m is the number of rows in the first matrix, n is the number of columns in the first matrix and the number of rows in the second, and p is the number of columns in the second matrix.

$$ m\underset{n}{\begin{bmatrix} \, \\ A \\ \,\end{bmatrix}} \quad
n\underset{p}{\begin{bmatrix}& B &\end{bmatrix}} = m\underset{p}{\begin{bmatrix} \, \\ C \\ \,\end{bmatrix}}
$$

$$ C_{i,k} = \displaystyle\sum_{j}A_{i,j}B_{j,k} $$

Multiplying a matrix with a vector:

$$ 
\begin{bmatrix} 3 & 4 \\ 5 & 6 \\ 7 & 8 \end{bmatrix}
\begin{bmatrix} 1 \\ 2 \end{bmatrix} = \begin{bmatrix} 3*1 + 4*2\\ 5*1+6*2 \\ 7*1+8*2 \end{bmatrix} = \begin{bmatrix} 11 \\ 17 \\ 23\end{bmatrix}
$$

Multiplying a matrix with a matrix:

$$ 
\begin{bmatrix} 3 & 4 \\ 5 & 6 \\ 7 & 8 \end{bmatrix}
\begin{bmatrix} 1 & 9\\ 2 & 0 \end{bmatrix} = \begin{bmatrix} 3*1 + 4*2 & 3*9+4*0\\ 5*1+6*2 & 5*9+6*0\\ 7*1+8*2 &7*9+8*0 \end{bmatrix} = \begin{bmatrix} 11 & 27\\ 17 & 45\\ 23&63\end{bmatrix}
$$

Matrix multiplication is typically not commutative: $$\boldsymbol{X}\boldsymbol{Y} \not= \boldsymbol{Y}\boldsymbol{X}$$

If both matrices are square, multiplying either way will work, but the results will usually be different.

Can represent the following regression as a matrix multiplication:

$$
\begin{bmatrix}
 y{_1} |\alpha + \beta x{_{1,1}} + \gamma x{_{1,2}} + ... + m_{-1}x{_{1,m_{-1}}} \\
 y{_2} | \alpha + \beta x{_{2,1}} + \gamma x{_{2,2}} + ... + m_{-1}x{_{2,m_{-1}}} \\
\vdots \\
 y{_n} |  \alpha + \beta x{_{n,1}} + \gamma x{_{n,2}} + ... + m_{-1}x{_{n,m_{-1}}}
\end{bmatrix} \\ \begin{bmatrix} y{_1} \\ y{_2} \\ \vdots \\ y{_n}\end{bmatrix} =\begin{bmatrix} 1 & X_{1,1} & X_{1,2} & \dots & X_{1,m_{-1}}\\ 1 & X_{2,1} & X_{2,2} & \dots & X_{2,m_{-1}} \\ \vdots \\ 1 & X_{n,1} & X_{n,2} & \dots & X_{n,m_{-1}} \end{bmatrix}
\begin{bmatrix} \alpha \\ \beta \\ \vdots \\ m_{-1}\end{bmatrix}
$$

$n$ cases tall, $m$ features wide.

